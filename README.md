LSTM-Activity-Recognition
=========================
LSTM with Google BlazePose for Activity Recognition
using 2D-Video or Web-Camera.  
  
Classifing activities
---------------------
- STAND  
- WALK  
- RUN  
- SIT  
- GREET (UP HANDS)  
- FALLDOWN  
- CROSS ARMS (STAND)  
- CROSS ARMS (SIT)  
- PUSH UP  
- CLAP  

Data
====================
Used *사람동작 영상 (Human Movement Video) dataset*.  
It's comprised of 50 subjects with max 4 people 12 angles.  
[https://aihub.or.kr/aidata/138](URL)

Examples
===========
![a25_s6_t1_color_complex-gifski-fast](https://user-images.githubusercontent.com/3463669/144547716-097c3fac-4dcf-4cee-a650-b5371fd65247.gif)
![C026100_001_complex-gifski-fast](https://user-images.githubusercontent.com/3463669/144547516-47ec894a-9d54-457e-91d4-937b0767ca29.gif)
  
# References
AI-Hub Datset : [https://aihub.or.kr/aidata/138](URL)  
blazepose : [https://github.com/vietanhdev/tf-blazepose](URL)  
opencv : [https://github.com/opencv/opencv](URL)  
tensorflow : [https://github.com/tensorflow/tensorflow](URL)  
keras : [https://github.com/keras-team/keras](URL)  
LSTM-Human-Activity-Recognition : [https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition](URL)
